# US-010: End-to-End Integration

**Status:** pending
**Model:** sonnet
**Component:** System
**Depends On:** US-001, US-002, US-003, US-004, US-005, US-006, US-007, US-008, US-009
**Traces To:** FR-047, FR-048, FR-049, FR-050

## Description

Implements an end-to-end integration test in `tests/integration/test_lifecycle.py` that simulates the full work unit lifecycle without any live network calls or database credentials. A simulated worker claims a `verify_finding` unit via the API, submits a result with mocked HTTP (justice.gov PDF fetches are stubbed), and the result is accepted and stored in `findings.db`. The test also verifies unit_id uniqueness across a batch.

## Files to Create / Modify

- `tests/integration/test_lifecycle.py` — integration test covering the full lifecycle for `verify_finding`, plus unit_id uniqueness assertion
- `tests/integration/fixtures/` — sample claim data JSON and mock HTTP response stubs used by the integration test

## Acceptance Criteria

- [ ] A simulated worker with no database credentials can claim a `verify_finding` unit via `GET /work` and receive a valid `WorkUnit` JSON response (FR-048)
- [ ] The worker submits a `POST /result` with mocked HTTP (justice.gov calls stubbed) and receives `accepted: true` (FR-048)
- [ ] The accepted finding is persisted to `findings.db` with non-null `worker_id` and `submitted_at` within 5 seconds of submission (FR-050)
- [ ] The stored finding's `submitted_at` timestamp is within 5 seconds of the test's submission time (FR-050)
- [ ] Generating 1,000 `verify_finding` units and collecting all `unit_id` values produces a Python set of size exactly 1,000 (no duplicates) (FR-049)
- [ ] The integration test requires no live network calls; all HTTP interactions with justice.gov are intercepted by `pytest-httpx` or `unittest.mock.patch` (FR-048, OQ-003 resolution)
- [ ] The integration test starts with a fresh in-memory or temp-dir `findings.db`; no leftover state from unit tests (FR-038)
- [ ] On system startup (ingest step at beginning of test), all three required JSON files are loaded and their record counts are logged (FR-047)
- [ ] If a required JSON file is absent, the integration test fails fast with a descriptive error (FR-047)
- [ ] `pytest tests/integration/` runs without configuration errors on a clean checkout (NFR-005)

## Notes

- Use `pytest` fixtures to wire up the full dependency graph: `IngestManager` -> `DatabaseAdapter` -> `WorkUnitGenerator` + `ValidationLayer` + `FindingsStore` -> FastAPI `TestClient`.
- Mock HTTP strategy: use `respx` (for `httpx`) or `responses` (for `requests`) to intercept HEAD requests from `resolve_efta()` and return 200 for known EFTA URLs, 404 for unknown ones.
- The `verify_finding` result submitted in the test should be well-formed per AC-002: `verdict`, `reasoning`, and `citations` with valid EFTA references.
- Unit_id uniqueness test: instantiate `WorkUnitGenerator` with a large enough claim pool (or a synthetic generator that produces 1,000 claims), call `generate_unit("verify_finding")` 1,000 times, collect `unit_id` values into a set, assert `len(unit_ids) == 1000`.
- Do not use `asyncio` for the integration test unless FastAPI's `TestClient` forces it — prefer the synchronous `TestClient` from `starlette.testclient` for simplicity.
- Place fixture data (sample claims JSON, mock EFTA mapping) in `tests/integration/fixtures/` and load them via `pathlib.Path(__file__).parent / "fixtures"`.
- The integration test is the final validation gate. All prior user stories must pass their unit tests before this test is expected to pass.
